{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec42feb-3d06-410e-b57e-63e58cf62f97",
   "metadata": {},
   "source": [
    "## Q1. Install MLflow\n",
    "\n",
    "To get started with MLflow you'll need to install the MLflow Python package.\n",
    "\n",
    "Once you installed the package, run the command `mlflow --version` and check the output.\n",
    "\n",
    "What's the version that you have?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b614eef-338b-423b-b1b2-6735e55a897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 2.22.0\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c42e0f-c46a-4864-bb13-cfec79f19e69",
   "metadata": {},
   "source": [
    "## Q2. Download and preprocess the data\n",
    "\n",
    "We'll use the Green Taxi Trip Records dataset to predict the duration of each trip. \n",
    "\n",
    "Download the data for January, February and March 2023 in parquet format from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page).\n",
    "\n",
    "Use the script `preprocess_data.py` located in the folder [`homework`](homework) to preprocess the data.\n",
    "\n",
    "The script will:\n",
    "\n",
    "* load the data from the folder `<TAXI_DATA_FOLDER>` (the folder where you have downloaded the data),\n",
    "* fit a `DictVectorizer` on the training set (January 2023 data),\n",
    "* save the preprocessed datasets and the `DictVectorizer` to disk.\n",
    "\n",
    "Your task is to download the datasets and then execute this command:\n",
    "\n",
    "```\n",
    "python preprocess_data.py --raw_data_path <TAXI_DATA_FOLDER> --dest_path ./output\n",
    "```\n",
    "\n",
    "Tip: go to `02-experiment-tracking/homework/` folder before executing the command and change the value of `<TAXI_DATA_FOLDER>` to the location where you saved the data.\n",
    "\n",
    "How many files were saved to `OUTPUT_FOLDER`?\n",
    "\n",
    "* 1\n",
    "* 3\n",
    "* **4**\n",
    "* 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b113642-8279-4070-bb66-d9047e5e9d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 93192\n",
      "-rw-rw-rw- 1 codespace codespace 47673370 Mar 20  2023 yellow_tripdata_2023-01.parquet\n",
      "-rw-rw-rw- 1 codespace codespace 47748012 May  1  2023 yellow_tripdata_2023-02.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6f2586-5a43-4de7-a429-dbbad3119540",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess_data.py --raw_data_path ../data --dest_path ../output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "793dc7db-1995-4c87-8902-e93ee54ba2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7016\n",
      "-rw-rw-rw- 1 codespace codespace  131004 May 16 17:51 dv.pkl\n",
      "-rw-rw-rw- 1 codespace codespace 2458698 May 16 17:51 test.pkl\n",
      "-rw-rw-rw- 1 codespace codespace 2374518 May 16 17:51 train.pkl\n",
      "-rw-rw-rw- 1 codespace codespace 2215824 May 16 17:51 val.pkl\n"
     ]
    }
   ],
   "source": [
    "! ls -l ../output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c46f5-d7d1-4788-b392-c9018c7bb3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
